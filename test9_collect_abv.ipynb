{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f496c0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import time\n",
    "from torch.distributions import Beta\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import BatchSampler, SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "# --- Masking Pipeline ---\n",
    "def apply_gaussian_blur(channel, ksize=5):\n",
    "    return cv2.GaussianBlur(channel, (ksize, ksize), 0)\n",
    "\n",
    "def adjust_brightness(channel, factor=1.2):\n",
    "    channel = np.clip(np.float32(channel) * factor, 0, 255)\n",
    "    return np.uint8(channel)\n",
    "\n",
    "def adjust_saturation_single_channel(channel, factor=1.5):\n",
    "    rgb = cv2.merge([channel, channel, channel])\n",
    "    hsv = cv2.cvtColor(rgb, cv2.COLOR_RGB2HSV)\n",
    "    hsv[..., 1] = np.clip(hsv[..., 1] * factor, 0, 255)\n",
    "    saturated = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "    return cv2.cvtColor(saturated, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def extract_center_value(channel, region_size=7, offset_y=10):\n",
    "    h, w = channel.shape\n",
    "    cx, cy = w // 2, h // 2\n",
    "    offsets = [-offset_y, 0, offset_y]\n",
    "    values = []\n",
    "    for off in offsets:\n",
    "        y1 = cy + off - region_size // 2\n",
    "        y2 = cy + off + region_size // 2\n",
    "        x1 = cx - region_size // 2\n",
    "        x2 = cx + region_size // 2\n",
    "        region = channel[y1:y2, x1:x2]\n",
    "        values.append(np.mean(region))\n",
    "    return np.mean(values)\n",
    "\n",
    "def extract_mask(channel, center_value, tolerance=25):\n",
    "    diff = np.abs(channel.astype(np.int16) - int(center_value))\n",
    "    mask = np.uint8(diff < tolerance) * 255\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    return mask\n",
    "\n",
    "def mask_quality(mask):\n",
    "    white = np.sum(mask == 255)\n",
    "    total = mask.size\n",
    "    return white / total\n",
    "\n",
    "def combine_masks(mask_r, mask_g, mask_b, threshold=127):\n",
    "    qualities = [mask_quality(mask_r), mask_quality(mask_g), mask_quality(mask_b)]\n",
    "    valid = [(0.05 < q < 0.29) for q in qualities]\n",
    "    masks = [mask_r, mask_g, mask_b]\n",
    "    used = [m for m, v in zip(masks, valid) if v]\n",
    "    if not used:\n",
    "        return np.zeros_like(mask_r)\n",
    "    weight = 1.0 / len(used)\n",
    "    combined = sum(weight * m for m in used)\n",
    "    _, binary = cv2.threshold(combined.astype(np.uint8), threshold, 255, cv2.THRESH_BINARY)\n",
    "    return binary\n",
    "\n",
    "def get_binary_mask(obs, frame_count, center_color):\n",
    "    r, g, b = cv2.split(obs)\n",
    "    r_proc = adjust_saturation_single_channel(adjust_brightness(apply_gaussian_blur(r, 5), factor=0.9), factor=1.5)\n",
    "    g_proc = adjust_saturation_single_channel(adjust_brightness(apply_gaussian_blur(g, 5), factor=0.9), factor=1.5)\n",
    "    b_proc = adjust_saturation_single_channel(adjust_brightness(apply_gaussian_blur(b, 5), factor=0.9), factor=1.5)\n",
    "\n",
    "    if frame_count == 15:\n",
    "        r_val = extract_center_value(r)\n",
    "        g_val = extract_center_value(g)\n",
    "        b_val = extract_center_value(b)\n",
    "        center_color[:] = [r_val, g_val, b_val]\n",
    "\n",
    "    if center_color[0] is not None:\n",
    "        mask_r = extract_mask(r_proc, center_color[0])\n",
    "        mask_g = extract_mask(g_proc, center_color[1])\n",
    "        mask_b = extract_mask(b_proc, center_color[2])\n",
    "        mask = combine_masks(mask_r, mask_g, mask_b)\n",
    "        # print(f\"Mask shape: {mask.shape}, Mask quality: {mask_quality(mask)}\")  # Debugging the mask\n",
    "        return mask\n",
    "    else:\n",
    "        return np.zeros_like(r)\n",
    "\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional Neural Network for PPO\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_stack):\n",
    "        super(Net, self).__init__()\n",
    "        self.cnn_base = nn.Sequential(  # input shape (4, 96, 96)\n",
    "            nn.Conv2d(img_stack, 8, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),  # activation\n",
    "            nn.Conv2d(8, 16, kernel_size=3, stride=2),  # (8, 47, 47)\n",
    "            nn.ReLU(),  # activation\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2),  # (16, 23, 23)\n",
    "            nn.ReLU(),  # activation\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2),  # (32, 11, 11)\n",
    "            nn.ReLU(),  # activation\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1),  # (64, 5, 5)\n",
    "            nn.ReLU(),  # activation\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1),  # (128, 3, 3)\n",
    "            nn.ReLU(),  # activation\n",
    "        )  # output shape (256, 1, 1)\n",
    "        self.v = nn.Sequential(nn.Linear(256, 100), nn.ReLU(), nn.Linear(100, 1))\n",
    "        self.fc = nn.Sequential(nn.Linear(256, 100), nn.ReLU())\n",
    "        self.alpha_head = nn.Sequential(nn.Linear(100, 3), nn.Softplus())\n",
    "        self.beta_head = nn.Sequential(nn.Linear(100, 3), nn.Softplus())\n",
    "        self.apply(self._weights_init)\n",
    "\n",
    "    @staticmethod\n",
    "    def _weights_init(m):\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            nn.init.xavier_uniform_(m.weight, gain=nn.init.calculate_gain('relu'))\n",
    "            nn.init.constant_(m.bias, 0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_base(x)\n",
    "        x = x.view(-1, 256)\n",
    "        v = self.v(x)\n",
    "        x = self.fc(x)\n",
    "        alpha = self.alpha_head(x) + 1\n",
    "        beta = self.beta_head(x) + 1\n",
    "\n",
    "        return (alpha, beta), v\n",
    "\n",
    "\n",
    "img_stack=4\n",
    "\n",
    "transition = np.dtype([('s', np.float64, (img_stack, 96, 96)), \n",
    "                       ('a', np.float64, (3,)), ('a_logp', np.float64),\n",
    "                       ('r', np.float64), ('s_', np.float64, (img_stack, 96, 96))])\n",
    "GAMMA=0.99\n",
    "EPOCH= 8 # beter than 10\n",
    "MAX_SIZE = 2000 ## CUDA out of mem for max_size=10000\n",
    "BATCH=128 \n",
    "EPS=0.1\n",
    "LEARNING_RATE = 0.001 # bettr than 0.005 or 0.002 \n",
    "action_repeat = 10\n",
    "\n",
    "def rgb2gray(rgb, norm=True):\n",
    "    # Convert RGB to grayscale using the standard formula\n",
    "    gray = np.dot(rgb[..., :3], [0.299, 0.587, 0.114])  # RGB to grayscale\n",
    "    if norm:\n",
    "        # Normalize the grayscale image to range [-1, 1]\n",
    "        gray = gray / 128.0 - 1.0\n",
    "    return gray\n",
    "class Agent():\n",
    "    \"\"\" Agent for training \"\"\"\n",
    "    \n",
    "    def __init__(self, device):\n",
    "        self.training_step = 0\n",
    "        self.net = Net(img_stack).double().to(device)\n",
    "        self.buffer = np.empty(MAX_SIZE, dtype=transition)\n",
    "        self.counter = 0\n",
    "        self.device = device\n",
    "        \n",
    "        self.optimizer = optim.Adam(self.net.parameters(), lr=LEARNING_RATE)  ## lr=1e-3\n",
    "\n",
    "    def select_action(self, state):\n",
    "        state = torch.from_numpy(state).double().to(self.device).unsqueeze(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            alpha, beta = self.net(state)[0]\n",
    "        dist = Beta(alpha, beta)\n",
    "        action = dist.sample()\n",
    "        a_logp = dist.log_prob(action).sum(dim=1)\n",
    "\n",
    "        action = action.squeeze().cpu().numpy()\n",
    "        a_logp = a_logp.item()\n",
    "        return action, a_logp\n",
    "\n",
    "\n",
    "    def store(self, transition):\n",
    "        self.buffer[self.counter] = transition\n",
    "        self.counter += 1\n",
    "        if self.counter == MAX_SIZE:\n",
    "            self.counter = 0\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "agent = Agent('cpu')\n",
    "\n",
    "class Wrapper:\n",
    "    \"\"\"\n",
    "    Environment wrapper for CarRacing \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env, img_stack=4, action_repeat=4):\n",
    "        self.env = env\n",
    "        self.img_stack = img_stack\n",
    "        self.action_repeat = action_repeat\n",
    "        self.die = False\n",
    "        self.stack = []\n",
    "        self.frame_count = 0\n",
    "        self.center_color = [None, None, None]\n",
    "        self.av_r = self.reward_memory()\n",
    "\n",
    "    def reset(self):\n",
    "        self.counter = 0\n",
    "        self.die = False\n",
    "        img_rgb, _ = self.env.reset()\n",
    "        img_gray = rgb2gray(img_rgb)\n",
    "        self.stack = [img_gray] * self.img_stack\n",
    "        return np.array(self.stack)\n",
    "\n",
    "    def step(self, action):\n",
    "        total_reward = 0\n",
    "        for _ in range(self.action_repeat):\n",
    "            action[0] = np.clip(action[0], -1.0, 1.0)\n",
    "            action[1] = np.clip(action[1], 0.0, 1.0)\n",
    "            action[2] = np.clip(action[2], 0.0, 1.0)\n",
    "            img_rgb, reward, done, truncated, info = self.env.step(action)\n",
    "\n",
    "            if self.die:\n",
    "                reward += 100\n",
    "            if np.mean(img_rgb[:, :, 1]) > 185.0:\n",
    "                reward -= 0.05\n",
    "\n",
    "            total_reward += reward\n",
    "            done = True if self.av_r(reward) <= -0.1 else done\n",
    "            if done or self.die:\n",
    "                break\n",
    "\n",
    "        img_gray = rgb2gray(img_rgb)\n",
    "        self.stack.pop(0)\n",
    "        self.stack.append(img_gray)\n",
    "        assert len(self.stack) == self.img_stack\n",
    "\n",
    "        # Compute binary mask here from img_rgb\n",
    "        binary_mask = self.get_binary_mask_from_rgb(img_rgb, self.frame_count, self.center_color)\n",
    "\n",
    "        return np.array(self.stack), total_reward, done, self.die, binary_mask\n",
    "\n",
    "    @staticmethod\n",
    "    def reward_memory():\n",
    "        count = 0\n",
    "        length = 100\n",
    "        history = np.zeros(length)\n",
    "\n",
    "        def memory(reward):\n",
    "            nonlocal count\n",
    "            history[count] = reward\n",
    "            count = (count + 1) % length\n",
    "            return np.mean(history)\n",
    "\n",
    "        return memory\n",
    "\n",
    "    \n",
    "agent = Agent('cpu')\n",
    "\n",
    "video_dir = \"/Applications/Files/SEM_7/MAJOR/RL/datavideos\"  # Path where videos will be saved\n",
    "os.makedirs(video_dir, exist_ok=True)  # Make sure the directory exists\n",
    "\n",
    "\n",
    "env = gym.make('CarRacing-v2', verbose=1, render_mode='rgb_aray', domain_randomize=False)\n",
    "# env = gym.wrappers.RecordVideo(env, video_dir, episode_trigger=lambda x: True)  # Record all episodes\n",
    "env_wrap = Wrapper(env)\n",
    "\n",
    "# Load Model\n",
    "def load(agent, directory, filename):\n",
    "    model_path = os.path.join(directory, filename)\n",
    "    agent.net.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# Play Function\n",
    "from collections import deque\n",
    "\n",
    "# Directory for saving the output\n",
    "output_dir = \"ppo_output_npz\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "def extract_data_npz(env_wrap, agent, n_episodes=50):\n",
    "    all_alphas = []\n",
    "    all_betas = []\n",
    "    all_vs = []\n",
    "    all_masks = []\n",
    "\n",
    "    for i_episode in range(n_episodes):\n",
    "        state = env_wrap.reset()\n",
    "        done = False\n",
    "        die = False\n",
    "        step = 0\n",
    "\n",
    "        episode_alphas = []\n",
    "        episode_betas = []\n",
    "        episode_vs = []\n",
    "        episode_masks = []\n",
    "\n",
    "        while not done and not die:\n",
    "            # Forward pass\n",
    "            state_tensor = torch.from_numpy(state).double().unsqueeze(0).to(agent.device)\n",
    "            with torch.no_grad():\n",
    "                (alpha, beta), v = agent.net(state_tensor)\n",
    "\n",
    "            alpha = alpha.squeeze().cpu().numpy()\n",
    "            beta = beta.squeeze().cpu().numpy()\n",
    "            v = v.item()\n",
    "            mask = get_binary_mask(state, step)\n",
    "\n",
    "            # Append step data\n",
    "            episode_alphas.append(alpha)\n",
    "            episode_betas.append(beta)\n",
    "            episode_vs.append(v)\n",
    "            episode_masks.append(mask)\n",
    "\n",
    "            # Take action\n",
    "            action, a_logp = agent.select_action(state)\n",
    "            next_state, reward, done, die = env_wrap.step(\n",
    "                action * np.array([2.0, 1.0, 1.0]) + np.array([-1.0, 0.0, 0.0])\n",
    "            )\n",
    "\n",
    "            state = next_state\n",
    "            step += 1\n",
    "\n",
    "        print(f\"Episode {i_episode+1} finished with {step} steps.\")\n",
    "\n",
    "        all_alphas.append(np.array(episode_alphas))  # (steps, 3)\n",
    "        all_betas.append(np.array(episode_betas))    # (steps, 3)\n",
    "        all_vs.append(np.array(episode_vs))          # (steps,)\n",
    "        all_masks.append(np.array(episode_masks))    # (steps, 96, 96)\n",
    "\n",
    "    # Save everything in .npz format\n",
    "    np.savez_compressed(\n",
    "        os.path.join(output_dir, \"ppo_50_episodes_data.npz\"),\n",
    "        alphas=all_alphas,\n",
    "        betas=all_betas,\n",
    "        values=all_vs,\n",
    "        masks=all_masks\n",
    "    )\n",
    "    print(f\"\\nSaved data to: {os.path.join(output_dir, 'ppo_50_episodes_data.npz')}\")\n",
    "\n",
    "load(agent, '/Applications/Files/SEM_7/MAJOR/RL/model', 'model_weights_best.pth')\n",
    "\n",
    "# Run and save\n",
    "extract_data_npz(env_wrap, agent, n_episodes=50)\n",
    "\n",
    "\n",
    "\n",
    "# play(env, agent, n_episodes=1)\n",
    "# /Users/divyansh/Downloads/model_weights_best.pth\n",
    "# Close the environment\n",
    "env.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
