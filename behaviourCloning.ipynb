{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a0133ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from gym.wrappers import GrayScaleObservation, FrameStack\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3fce961a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CarRacing-v2', domain_randomize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "98ffef68",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, _ = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0bbe5809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 96, 3)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "79def5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xbf7a9dd60>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "215d11e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "step() missing 1 required positional argument: 'action'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[115], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(\u001b[38;5;129;01mnot\u001b[39;00m die \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done):\n\u001b[0;32m----> 6\u001b[0m     obs, reward, term, trunc, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: step() missing 1 required positional argument: 'action'"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    die = False\n",
    "    done = False\n",
    "\n",
    "    while(not die or not done):\n",
    "        obs, reward, term, trunc, info = env.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389ee143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎮 Starting Episode 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 16:17:29.370 python[45552:2019561] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-04-29 16:17:29.371 python[45552:2019561] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n",
      "/opt/miniconda3/envs/myenv38/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving episode 1: Observations shape (1000, 96, 96, 3), Masks shape (1000, 96, 96), Actions shape (1000, 3)\n",
      "✅ Saved Episode 1 to expert_runs/run_16.npz\n",
      "🎮 Starting Episode 2/5\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "video system not initialized",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 293\u001b[0m\n\u001b[1;32m    290\u001b[0m         exit()\n\u001b[1;32m    292\u001b[0m \u001b[38;5;66;03m# Get the action from user input\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[43mget_action_from_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# Get the binary mask for the raw observation after the action\u001b[39;00m\n\u001b[1;32m    296\u001b[0m mask \u001b[38;5;241m=\u001b[39m get_binary_mask(raw_obs, frame_count, center_color)\n",
      "Cell \u001b[0;32mIn[6], line 235\u001b[0m, in \u001b[0;36mget_action_from_keys\u001b[0;34m()\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_action_from_keys\u001b[39m():\n\u001b[0;32m--> 235\u001b[0m     keys \u001b[38;5;241m=\u001b[39m \u001b[43mpygame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_pressed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m     action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m])\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m keys[K_LEFT] \u001b[38;5;129;01mor\u001b[39;00m keys[K_a]:\n",
      "\u001b[0;31merror\u001b[0m: video system not initialized"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# import gym\n",
    "# import numpy as np\n",
    "# import pygame\n",
    "# import cv2\n",
    "# import os\n",
    "# from pygame.locals import *\n",
    "\n",
    "# # --- Masking Pipeline ---\n",
    "# def apply_gaussian_blur(channel, ksize=5):\n",
    "#     return cv2.GaussianBlur(channel, (ksize, ksize), 0)\n",
    "\n",
    "# def adjust_brightness(channel, factor=1.2):\n",
    "#     channel = np.clip(np.float32(channel) * factor, 0, 255)\n",
    "#     return np.uint8(channel)\n",
    "\n",
    "# def adjust_saturation_single_channel(channel, factor=1.5):\n",
    "#     rgb = cv2.merge([channel, channel, channel])\n",
    "#     hsv = cv2.cvtColor(rgb, cv2.COLOR_RGB2HSV)\n",
    "#     hsv[..., 1] = np.clip(hsv[..., 1] * factor, 0, 255)\n",
    "#     saturated = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "#     return cv2.cvtColor(saturated, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# def extract_center_value(channel, region_size=7, offset_y=10):\n",
    "#     h, w = channel.shape\n",
    "#     cx, cy = w // 2, h // 2\n",
    "#     offsets = [-offset_y, 0, offset_y]\n",
    "#     values = []\n",
    "#     for off in offsets:\n",
    "#         y1 = cy + off - region_size // 2\n",
    "#         y2 = cy + off + region_size // 2\n",
    "#         x1 = cx - region_size // 2\n",
    "#         x2 = cx + region_size // 2\n",
    "#         region = channel[y1:y2, x1:x2]\n",
    "#         values.append(np.mean(region))\n",
    "#     return np.mean(values)\n",
    "\n",
    "# def extract_mask(channel, center_value, tolerance=25):\n",
    "#     diff = np.abs(channel.astype(np.int16) - int(center_value))\n",
    "#     mask = np.uint8(diff < tolerance) * 255\n",
    "#     kernel = np.ones((3, 3), np.uint8)\n",
    "#     mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "#     mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "#     return mask\n",
    "\n",
    "# def mask_quality(mask):\n",
    "#     white = np.sum(mask == 255)\n",
    "#     total = mask.size\n",
    "#     return white / total\n",
    "\n",
    "# def combine_masks(mask_r, mask_g, mask_b, threshold=127):\n",
    "#     qualities = [mask_quality(mask_r), mask_quality(mask_g), mask_quality(mask_b)]\n",
    "#     valid = [(0.05 < q < 0.29) for q in qualities]\n",
    "#     masks = [mask_r, mask_g, mask_b]\n",
    "#     used = [m for m, v in zip(masks, valid) if v]\n",
    "#     if not used:\n",
    "#         return np.zeros_like(mask_r)\n",
    "#     weight = 1.0 / len(used)\n",
    "#     combined = sum(weight * m for m in used)\n",
    "#     _, binary = cv2.threshold(combined.astype(np.uint8), threshold, 255, cv2.THRESH_BINARY)\n",
    "#     return binary\n",
    "\n",
    "# def get_binary_mask(obs, frame_count, center_color):\n",
    "#     r, g, b = cv2.split(obs)\n",
    "#     r_proc = adjust_saturation_single_channel(adjust_brightness(apply_gaussian_blur(r, 5), factor=0.9), factor=1.5)\n",
    "#     g_proc = adjust_saturation_single_channel(adjust_brightness(apply_gaussian_blur(g, 5), factor=0.9), factor=1.5)\n",
    "#     b_proc = adjust_saturation_single_channel(adjust_brightness(apply_gaussian_blur(b, 5), factor=0.9), factor=1.5)\n",
    "\n",
    "#     if frame_count == 15:\n",
    "#         r_val = extract_center_value(r)\n",
    "#         g_val = extract_center_value(g)\n",
    "#         b_val = extract_center_value(b)\n",
    "#         center_color[:] = [r_val, g_val, b_val]\n",
    "\n",
    "#     if center_color[0] is not None:\n",
    "#         mask_r = extract_mask(r_proc, center_color[0])\n",
    "#         mask_g = extract_mask(g_proc, center_color[1])\n",
    "#         mask_b = extract_mask(b_proc, center_color[2])\n",
    "#         return combine_masks(mask_r, mask_g, mask_b)\n",
    "#     else:\n",
    "#         return np.zeros_like(r)\n",
    "\n",
    "# # --- Action mapping ---\n",
    "# def get_action_from_keys():\n",
    "#     keys = pygame.key.get_pressed()\n",
    "#     action = np.array([0.0, 0.0, 0.0])\n",
    "#     if keys[K_LEFT] or keys[K_a]:\n",
    "#         action[0] = -1.0\n",
    "#     if keys[K_RIGHT] or keys[K_d]:\n",
    "#         action[0] = 1.0\n",
    "#     if keys[K_UP] or keys[K_w]:\n",
    "#         action[1] = 1.0\n",
    "#     if keys[K_DOWN] or keys[K_s]:\n",
    "#         action[2] = 0.8\n",
    "#     return action\n",
    "\n",
    "# # --- Setup ---\n",
    "# pygame.init()\n",
    "# screen = pygame.display.set_mode((96, 96))\n",
    "# pygame.display.set_caption(\"CarRacing Manual Control with Mask\")\n",
    "# clock = pygame.time.Clock()\n",
    "\n",
    "# save_dir = \"expert_runs\"\n",
    "# os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# env = gym.make(\"CarRacing-v2\", render_mode=\"rgb_array\", domain_randomize=True)\n",
    "\n",
    "# for ep_num in range(5):\n",
    "#     print(f\"🎮 Starting Episode {ep_num+1}/50\")\n",
    "#     obs, _ = env.reset()\n",
    "#     done = False\n",
    "#     truncated = False\n",
    "\n",
    "#     frame_count = 0\n",
    "#     center_color = [None, None, None]\n",
    "#     obs_masks = []\n",
    "#     actions = []\n",
    "\n",
    "#     while not (done or truncated):\n",
    "#         frame = env.render()\n",
    "#         # resized_frame = cv2.resize(frame)\n",
    "#         surface = pygame.surfarray.make_surface(np.transpose(frame, (1, 0, 2)))\n",
    "#         screen.blit(surface, (0, 0))\n",
    "#         pygame.display.flip()\n",
    "\n",
    "#         for event in pygame.event.get():\n",
    "#             if event.type == QUIT:\n",
    "#                 done = True\n",
    "#                 pygame.quit()\n",
    "#                 env.close()\n",
    "#                 exit()\n",
    "\n",
    "#         action = get_action_from_keys()\n",
    "#         mask = get_binary_mask(frame, frame_count, center_color)\n",
    "\n",
    "#         obs_masks.append(mask)\n",
    "#         actions.append(action)\n",
    "\n",
    "#         _, _, done, truncated, _ = env.step(action)\n",
    "#         clock.tick(60)\n",
    "#         frame_count += 1\n",
    "\n",
    "#     obs_masks = np.array(obs_masks)\n",
    "#     actions = np.array(actions)\n",
    "#     filename = os.path.join(save_dir, f\"run_{ep_num+5:02d}.npz\")\n",
    "#     np.savez_compressed(filename, obs=obs_masks, acts=actions)\n",
    "#     print(f\"✅ Saved Episode {ep_num+1} to {filename}\")\n",
    "\n",
    "# pygame.quit()\n",
    "# env.close()\n",
    "import gym\n",
    "import numpy as np\n",
    "import pygame\n",
    "import os\n",
    "from pygame.locals import *\n",
    "import cv2\n",
    "\n",
    "# --- Masking Pipeline ---\n",
    "def apply_gaussian_blur(channel, ksize=5):\n",
    "    return cv2.GaussianBlur(channel, (ksize, ksize), 0)\n",
    "\n",
    "def adjust_brightness(channel, factor=1.2):\n",
    "    channel = np.clip(np.float32(channel) * factor, 0, 255)\n",
    "    return np.uint8(channel)\n",
    "\n",
    "def adjust_saturation_single_channel(channel, factor=1.5):\n",
    "    rgb = cv2.merge([channel, channel, channel])\n",
    "    hsv = cv2.cvtColor(rgb, cv2.COLOR_RGB2HSV)\n",
    "    hsv[..., 1] = np.clip(hsv[..., 1] * factor, 0, 255)\n",
    "    saturated = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "    return cv2.cvtColor(saturated, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def extract_center_value(channel, region_size=7, offset_y=10):\n",
    "    h, w = channel.shape\n",
    "    cx, cy = w // 2, h // 2\n",
    "    offsets = [-offset_y, 0, offset_y]\n",
    "    values = []\n",
    "    for off in offsets:\n",
    "        y1 = cy + off - region_size // 2\n",
    "        y2 = cy + off + region_size // 2\n",
    "        x1 = cx - region_size // 2\n",
    "        x2 = cx + region_size // 2\n",
    "        region = channel[y1:y2, x1:x2]\n",
    "        values.append(np.mean(region))\n",
    "    return np.mean(values)\n",
    "\n",
    "def extract_mask(channel, center_value, tolerance=25):\n",
    "    diff = np.abs(channel.astype(np.int16) - int(center_value))\n",
    "    mask = np.uint8(diff < tolerance) * 255\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    return mask\n",
    "\n",
    "def mask_quality(mask):\n",
    "    white = np.sum(mask == 255)\n",
    "    total = mask.size\n",
    "    return white / total\n",
    "\n",
    "def combine_masks(mask_r, mask_g, mask_b, threshold=127):\n",
    "    qualities = [mask_quality(mask_r), mask_quality(mask_g), mask_quality(mask_b)]\n",
    "    valid = [(0.05 < q < 0.29) for q in qualities]\n",
    "    masks = [mask_r, mask_g, mask_b]\n",
    "    used = [m for m, v in zip(masks, valid) if v]\n",
    "    if not used:\n",
    "        return np.zeros_like(mask_r)\n",
    "    weight = 1.0 / len(used)\n",
    "    combined = sum(weight * m for m in used)\n",
    "    _, binary = cv2.threshold(combined.astype(np.uint8), threshold, 255, cv2.THRESH_BINARY)\n",
    "    return binary\n",
    "\n",
    "def get_binary_mask(obs, frame_count, center_color):\n",
    "    r, g, b = cv2.split(obs)\n",
    "    r_proc = adjust_saturation_single_channel(adjust_brightness(apply_gaussian_blur(r, 5), factor=0.9), factor=1.5)\n",
    "    g_proc = adjust_saturation_single_channel(adjust_brightness(apply_gaussian_blur(g, 5), factor=0.9), factor=1.5)\n",
    "    b_proc = adjust_saturation_single_channel(adjust_brightness(apply_gaussian_blur(b, 5), factor=0.9), factor=1.5)\n",
    "\n",
    "    if frame_count == 15:\n",
    "        r_val = extract_center_value(r)\n",
    "        g_val = extract_center_value(g)\n",
    "        b_val = extract_center_value(b)\n",
    "        center_color[:] = [r_val, g_val, b_val]\n",
    "\n",
    "    if center_color[0] is not None:\n",
    "        mask_r = extract_mask(r_proc, center_color[0])\n",
    "        mask_g = extract_mask(g_proc, center_color[1])\n",
    "        mask_b = extract_mask(b_proc, center_color[2])\n",
    "        mask = combine_masks(mask_r, mask_g, mask_b)\n",
    "        # print(f\"Mask shape: {mask.shape}, Mask quality: {mask_quality(mask)}\")  # Debugging the mask\n",
    "        return mask\n",
    "    else:\n",
    "        return np.zeros_like(r)\n",
    "\n",
    "# --- Action mapping ---\n",
    "def get_action_from_keys():\n",
    "    keys = pygame.key.get_pressed()\n",
    "    action = np.array([0.0, 0.0, 0.0])\n",
    "    if keys[K_LEFT] or keys[K_a]:\n",
    "        action[0] = -1.0\n",
    "    if keys[K_RIGHT] or keys[K_d]:\n",
    "        action[0] = 1.0\n",
    "    if keys[K_UP] or keys[K_w]:\n",
    "        action[1] = 1.0\n",
    "    if keys[K_DOWN] or keys[K_s]:\n",
    "        action[2] = 0.8\n",
    "    return action\n",
    "\n",
    "# --- Setup ---\n",
    "pygame.init()\n",
    "screen = pygame.display.set_mode((600, 600))  # Adjusted screen size for better human interaction\n",
    "pygame.display.set_caption(\"CarRacing Manual Control with Mask\")\n",
    "\n",
    "save_dir = \"expert_runs\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Set up the gym environment with \"human\" mode for rendering\n",
    "env = gym.make(\"CarRacing-v2\", render_mode=\"human\", domain_randomize=True)\n",
    "\n",
    "# --- Main Loop ---\n",
    "for ep_num in range(5):\n",
    "    print(f\"🎮 Starting Episode {ep_num+1}/5\")\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "    truncated = False\n",
    "\n",
    "    frame_count = 0\n",
    "    obs_data = []\n",
    "    mask_data = []\n",
    "    actions = []\n",
    "\n",
    "    center_color = [None, None, None]  # Used for calculating the color center over time\n",
    "\n",
    "    while not (done or truncated):\n",
    "        # Render the environment for human visualization\n",
    "        # env.render(mode=\"human\")\n",
    "\n",
    "        # The raw observation after taking the action\n",
    "        raw_obs = obs  # This is the observation returned by env.step() in the next iteration\n",
    "\n",
    "        # Convert the frame to a surface for pygame\n",
    "        surface = pygame.surfarray.make_surface(np.transpose(raw_obs, (1, 0, 2)))\n",
    "        screen.blit(surface, (0, 0))\n",
    "        pygame.display.flip()\n",
    "\n",
    "        # Handle pygame events (like quitting the environment)\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == QUIT:\n",
    "                done = True\n",
    "                pygame.quit()\n",
    "                env.close()\n",
    "                exit()\n",
    "\n",
    "        # Get the action from user input\n",
    "        action = get_action_from_keys()\n",
    "\n",
    "        # Get the binary mask for the raw observation after the action\n",
    "        mask = get_binary_mask(raw_obs, frame_count, center_color)\n",
    "\n",
    "        # Append raw observation, mask, and action\n",
    "        obs_data.append(raw_obs)\n",
    "        mask_data.append(mask)\n",
    "        actions.append(action)\n",
    "\n",
    "        # Debugging: print the size of the mask and check if it's empty\n",
    "        # print(f\"Frame {frame_count}: Mask size {mask.shape}, Mask max value {np.max(mask)}\")\n",
    "\n",
    "        # Take action in the environment and get the next observation\n",
    "        obs, _, done, truncated, _ = env.step(action)\n",
    "        frame_count += 1\n",
    "\n",
    "    # Save the collected raw observations, masks, and actions\n",
    "    obs_data = np.array(obs_data)\n",
    "    mask_data = np.array(mask_data)\n",
    "    actions = np.array(actions)\n",
    "\n",
    "    # Debugging: check the shapes of the saved data\n",
    "    print(f\"Saving episode {ep_num+1}: Observations shape {obs_data.shape}, Masks shape {mask_data.shape}, Actions shape {actions.shape}\")\n",
    "\n",
    "    # Save to a compressed npz file for this episode\n",
    "    filename = os.path.join(save_dir, f\"run_{ep_num+16:02d}.npz\")\n",
    "    np.savez_compressed(filename, obs=obs_data, masks=mask_data, acts=actions)\n",
    "    print(f\"✅ Saved Episode {ep_num+1} to {filename}\")\n",
    "\n",
    "pygame.quit()\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a3925b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed and added run_08.npz\n",
      "✅ Processed and added run_04.npz\n",
      "✅ Processed and added run_05.npz\n",
      "✅ Processed and added run_07.npz\n",
      "✅ Processed and added run_06.npz\n",
      "✅ Processed and added run_02.npz\n",
      "✅ Processed and added run_03.npz\n",
      "✅ Processed and added run_01.npz\n",
      "✅ Saved final dataset to expert_runs/final_dataset.pt (normalized, PyTorch .pt format)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def process_and_save_all_in_one(directory, output_filename=\"final_dataset.pt\"):\n",
    "    # Get a list of all .npz files in the directory\n",
    "    files = [f for f in os.listdir(directory) if f.endswith('.npz')]\n",
    "    \n",
    "    if not files:\n",
    "        print(\"No .npz files found in the directory.\")\n",
    "        return\n",
    "    \n",
    "    all_masks = []\n",
    "    all_actions = []\n",
    "\n",
    "    for file in files:\n",
    "        file_path = os.path.join(directory, file)\n",
    "        try:\n",
    "            data = np.load(file_path)\n",
    "\n",
    "            if 'masks' in data and 'acts' in data:\n",
    "                masks = data['masks']\n",
    "                actions = data['acts']\n",
    "\n",
    "                if len(masks) > 30:\n",
    "                    masks = masks[11:-15]\n",
    "                    actions = actions[11:-15]\n",
    "\n",
    "                    all_masks.append(masks)\n",
    "                    all_actions.append(actions)\n",
    "                    print(f\"✅ Processed and added {file}\")\n",
    "                else:\n",
    "                    print(f\"⚠️ Skipped {file} — not enough frames.\")\n",
    "            else:\n",
    "                print(f\"⚠️ {file} missing 'masks' or 'acts'.\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {file}: {e}\")\n",
    "\n",
    "    if all_masks and all_actions:\n",
    "        all_masks = np.concatenate(all_masks, axis=0)  # (N, 96, 96)\n",
    "        all_actions = np.concatenate(all_actions, axis=0)  # (N, 3)\n",
    "\n",
    "        # ✅ Normalize masks to [0, 1] range\n",
    "        all_masks = all_masks.astype(np.float32) / 255.0\n",
    "\n",
    "        # Convert to torch tensors and add channel dimension\n",
    "        obs_tensor = torch.tensor(all_masks).unsqueeze(1)  # (N, 1, 96, 96)\n",
    "        acts_tensor = torch.tensor(all_actions, dtype=torch.float32)  # (N, 3)\n",
    "\n",
    "        save_path = os.path.join(directory, output_filename)\n",
    "        torch.save({'obs': obs_tensor, 'acts': acts_tensor}, save_path)\n",
    "        print(f\"✅ Saved final dataset to {save_path} (normalized, PyTorch .pt format)\")\n",
    "    else:\n",
    "        print(\"❌ No valid data found to save.\")\n",
    "\n",
    "# Usage\n",
    "directory = \"expert_runs\"  # Replace with your directory path\n",
    "process_and_save_all_in_one(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "63bc6a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import torch\n",
    "\n",
    "# def preprocess_npz_dataset(npz_dir, save_path):\n",
    "#     all_obs = []\n",
    "#     all_acts = []\n",
    "\n",
    "#     for fname in os.listdir(npz_dir):\n",
    "#         if not fname.endswith('.npz'):\n",
    "#             continue\n",
    "#         data = np.load(os.path.join(npz_dir, fname))\n",
    "#         obs = data['obs'][15:]  # Remove first 15 frames\n",
    "#         acts = data['acts'][15:]\n",
    "#         all_obs.append(obs)\n",
    "#         all_acts.append(acts)\n",
    "\n",
    "#     # Stack everything\n",
    "#     all_obs = np.concatenate(all_obs, axis=0)  # shape: (N, 96, 96)\n",
    "#     all_acts = np.concatenate(all_acts, axis=0)  # shape: (N, 3)\n",
    "\n",
    "#     # Normalize obs to [0.0, 1.0] and add channel dimension\n",
    "#     all_obs = all_obs.astype(np.float32) / 255.0\n",
    "#     all_obs = np.expand_dims(all_obs, axis=1)  # shape: (N, 1, 96, 96)\n",
    "\n",
    "#     # Convert to torch tensors\n",
    "#     obs_tensor = torch.tensor(all_obs, dtype=torch.float32)\n",
    "#     act_tensor = torch.tensor(all_acts, dtype=torch.float32)\n",
    "\n",
    "#     # Save as a single .pt file\n",
    "#     torch.save({'obs': obs_tensor, 'acts': act_tensor}, save_path)\n",
    "#     print(f\"✅ Saved processed dataset to {save_path}\")\n",
    "\n",
    "# # Run preprocessing\n",
    "# preprocess_npz_dataset('expert_runs', 'final_dataset.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2ee01b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BehaviorCloningDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_path, stack_size=4):\n",
    "        data = torch.load(data_path)\n",
    "        self.obs = data['obs']  # (N, 1, 96, 96)\n",
    "        self.acts = data['acts']  # (N, 3)\n",
    "        self.stack_size = stack_size\n",
    "\n",
    "        assert len(self.obs) >= stack_size, \"Not enough frames to create stacks\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.obs) - self.stack_size + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get a list of tensors to stack\n",
    "        obs_stack = [self.obs[idx + i] for i in range(self.stack_size)]  # list of (1, 96, 96)\n",
    "        obs_stack = torch.cat(obs_stack, dim=0)  # (4, 96, 96)\n",
    "\n",
    "        act = self.acts[idx + self.stack_size - 1]  # use action from last frame in stack\n",
    "        return obs_stack, act\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c1db901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TrackFeatureCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(4, 16, kernel_size=5, stride=2, padding=2)  # Changed input channels to 4\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2, padding=2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 6 * 6, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))  # (B, 4, 96, 96) → (B, 16, 48, 48)\n",
    "        x = F.relu(self.conv2(x))  # (B, 32, 24, 24)\n",
    "        x = F.relu(self.conv3(x))  # (B, 64, 12, 12)\n",
    "        x = F.relu(self.conv4(x))  # (B, 64, 6, 6)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6f3c07a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset loaded!\n",
      "Observations shape: torch.Size([7511, 1, 96, 96])\n",
      "Actions shape: torch.Size([7511, 3])\n",
      "Obs dtype: torch.float32, min: 0.0, max: 1.0\n",
      "Acts dtype: torch.float32, min: -1.0, max: 1.0\n",
      "Sample 0 action: tensor([0., 0., 0.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qj/nwy8w3y94qd1w66kj2j_mn400000gn/T/ipykernel_6661/4240038609.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(\"expert_runs/final_dataset.pt\")\n"
     ]
    }
   ],
   "source": [
    "# Load saved .pt dataset\n",
    "data = torch.load(\"expert_runs/final_dataset.pt\")\n",
    "\n",
    "obs = data['obs']  # shape: (N, 1, 96, 96)\n",
    "acts = data['acts']  # shape: (N, 3)\n",
    "\n",
    "# Basic checks\n",
    "print(\"✅ Dataset loaded!\")\n",
    "print(f\"Observations shape: {obs.shape}\")\n",
    "print(f\"Actions shape: {acts.shape}\")\n",
    "\n",
    "# Check data type and range\n",
    "print(f\"Obs dtype: {obs.dtype}, min: {obs.min()}, max: {obs.max()}\")\n",
    "print(f\"Acts dtype: {acts.dtype}, min: {acts.min()}, max: {acts.max()}\")\n",
    "\n",
    "# Check one sample\n",
    "i = 0\n",
    "print(f\"Sample {i} action: {acts[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "fda6fff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7511, 1, 96, 96])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "272e8e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qj/nwy8w3y94qd1w66kj2j_mn400000gn/T/ipykernel_6661/1401308735.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(data_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Epoch [1/5] - Loss: 0.0513\n",
      "📦 Epoch [2/5] - Loss: 0.0448\n",
      "📦 Epoch [3/5] - Loss: 0.0405\n",
      "📦 Epoch [4/5] - Loss: 0.0380\n",
      "📦 Epoch [5/5] - Loss: 0.0357\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "# Load dataset\n",
    "dataset = BehaviorCloningDataset('expert_runs/final_dataset.pt')\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Initialize model, loss, optimizer\n",
    "model = TrackFeatureCNN()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Train loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for obs_batch, act_batch in dataloader:\n",
    "        obs_batch = obs_batch.to(device)\n",
    "        act_batch = act_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(obs_batch)\n",
    "        loss = criterion(outputs, act_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    print(f\"📦 Epoch [{epoch+1}/{num_epochs}] - Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9d5e4c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'expert_runs/model_full.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38173ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qj/nwy8w3y94qd1w66kj2j_mn400000gn/T/ipykernel_6661/1220192667.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load('expert_runs/model_full.pth')\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# BBEHAVIOUR CLONING WORKING\n",
    "\n",
    "import torch\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import cv2\n",
    "from collections import deque\n",
    "\n",
    "# Load trained model\n",
    "model = torch.load('expert_runs/model_full.pth')\n",
    "model.eval()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Set up environment\n",
    "env = gym.make(\"CarRacing-v2\", render_mode=\"human\", domain_randomize=True)\n",
    "obs, _ = env.reset()\n",
    "done = False\n",
    "\n",
    "# Init stack of 4 binary masks (grayscale 96x96)\n",
    "frame_stack = deque(maxlen=4)\n",
    "center_color = [None, None, None]\n",
    "frame_count = 0\n",
    "\n",
    "# Fill with initial identical masks\n",
    "initial_mask = get_binary_mask(obs, frame_count, center_color) / 255.0  # normalize\n",
    "for _ in range(4):\n",
    "    frame_stack.append(initial_mask)\n",
    "\n",
    "while not done:\n",
    "    # Stack into (4, 96, 96), normalize already done\n",
    "    stack_np = np.stack(frame_stack, axis=0)\n",
    "    input_tensor = torch.tensor(stack_np, dtype=torch.float32).unsqueeze(0).to(device)  # (1, 4, 96, 96)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        action = model(input_tensor).squeeze().cpu().numpy()\n",
    "\n",
    "    action[0] = np.clip(action[0], -1.0, 1.0)\n",
    "    action[1] = np.clip(action[1], 0.0, 1.0)\n",
    "    action[2] = np.clip(action[2], 0.0, 1.0)\n",
    "\n",
    "    obs, _, terminated, truncated, _ = env.step(action)\n",
    "    done = terminated or truncated\n",
    "\n",
    "    frame_count += 1\n",
    "    new_mask = get_binary_mask(obs, frame_count, center_color) / 255.0\n",
    "    frame_stack.append(new_mask)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5e1eed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "211ba2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383a2193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fcc702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00705e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 18:19:19.298 python[5420:2321156] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-04-29 18:19:19.298 python[5420:2321156] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n",
      "/var/folders/qj/nwy8w3y94qd1w66kj2j_mn400000gn/T/ipykernel_5420/1697217655.py:143: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bc_model= torch.load('expert_runs/model_full.pth')  # Load your BC model here\n",
      "/var/folders/qj/nwy8w3y94qd1w66kj2j_mn400000gn/T/ipykernel_5420/1697217655.py:218: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ppo_loss = calculate_loss(alpha, beta, v, torch.tensor(action).to(device), log_probs, advantage)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 226\u001b[0m\n\u001b[1;32m    223\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Step in the environment with the action\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m obs, _, terminated, truncated, _ \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m done \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n\u001b[1;32m    228\u001b[0m frame_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/myenv38/lib/python3.8/site-packages/gymnasium/wrappers/time_limit.py:57\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m     47\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/myenv38/lib/python3.8/site-packages/gymnasium/wrappers/order_enforcing.py:56\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/myenv38/lib/python3.8/site-packages/gymnasium/wrappers/env_checker.py:49\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_step:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43menv_step_passive_checker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/myenv38/lib/python3.8/site-packages/gymnasium/utils/passive_env_checker.py:208\u001b[0m, in \u001b[0;36menv_step_passive_checker\u001b[0;34m(env, action)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"A passive check for the environment step, investigating the returning data then returning the data unchanged.\"\"\"\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;66;03m# We don't check the action as for some environments then out-of-bounds values can be given\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    210\u001b[0m     result, \u001b[38;5;28mtuple\u001b[39m\n\u001b[1;32m    211\u001b[0m ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpects step result to be a tuple, actual type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(result)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/myenv38/lib/python3.8/site-packages/gymnasium/envs/box2d/car_racing.py:537\u001b[0m, in \u001b[0;36mCarRacing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontinuous:\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcar\u001b[38;5;241m.\u001b[39msteer(\u001b[38;5;241m-\u001b[39maction[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 537\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcar\u001b[38;5;241m.\u001b[39mgas(\u001b[43maction\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcar\u001b[38;5;241m.\u001b[39mbrake(action[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import cv2\n",
    "from collections import deque\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Beta\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "# --- PPO Model ---\n",
    "class PPO(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PPO, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(4, 16, kernel_size=5, stride=2, padding=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2, padding=2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 6 * 6, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)  # Output alpha, beta for Beta distribution\n",
    "        self.fc3 = nn.Linear(128, 1)  # Output value function (v)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        alpha_beta = self.fc2(x)  # Parameters for Beta distribution\n",
    "        v = self.fc3(x)  # Value function\n",
    "        alpha, beta = torch.exp(alpha_beta[:, 0]), torch.exp(alpha_beta[:, 1])\n",
    "        return alpha, beta, v\n",
    "\n",
    "\n",
    "class TrackFeatureCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(4, 16, kernel_size=5, stride=2, padding=2)  # Changed input channels to 4\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2, padding=2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 6 * 6, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))  # (B, 4, 96, 96) → (B, 16, 48, 48)\n",
    "        x = F.relu(self.conv2(x))  # (B, 32, 24, 24)\n",
    "        x = F.relu(self.conv3(x))  # (B, 64, 12, 12)\n",
    "        x = F.relu(self.conv4(x))  # (B, 64, 6, 6)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "\n",
    "# --- Masking Pipeline ---\n",
    "def apply_gaussian_blur(channel, ksize=5):\n",
    "    return cv2.GaussianBlur(channel, (ksize, ksize), 0)\n",
    "\n",
    "def adjust_brightness(channel, factor=1.2):\n",
    "    channel = np.clip(np.float32(channel) * factor, 0, 255)\n",
    "    return np.uint8(channel)\n",
    "\n",
    "def adjust_saturation_single_channel(channel, factor=1.5):\n",
    "    rgb = cv2.merge([channel, channel, channel])\n",
    "    hsv = cv2.cvtColor(rgb, cv2.COLOR_RGB2HSV)\n",
    "    hsv[..., 1] = np.clip(hsv[..., 1] * factor, 0, 255)\n",
    "    saturated = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "    return cv2.cvtColor(saturated, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def extract_center_value(channel, region_size=7, offset_y=10):\n",
    "    h, w = channel.shape\n",
    "    cx, cy = w // 2, h // 2\n",
    "    offsets = [-offset_y, 0, offset_y]\n",
    "    values = []\n",
    "    for off in offsets:\n",
    "        y1 = cy + off - region_size // 2\n",
    "        y2 = cy + off + region_size // 2\n",
    "        x1 = cx - region_size // 2\n",
    "        x2 = cx + region_size // 2\n",
    "        region = channel[y1:y2, x1:x2]\n",
    "        values.append(np.mean(region))\n",
    "    return np.mean(values)\n",
    "\n",
    "def extract_mask(channel, center_value, tolerance=25):\n",
    "    diff = np.abs(channel.astype(np.int16) - int(center_value))\n",
    "    mask = np.uint8(diff < tolerance) * 255\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    return mask\n",
    "\n",
    "def mask_quality(mask):\n",
    "    white = np.sum(mask == 255)\n",
    "    total = mask.size\n",
    "    return white / total\n",
    "\n",
    "def combine_masks(mask_r, mask_g, mask_b, threshold=127):\n",
    "    qualities = [mask_quality(mask_r), mask_quality(mask_g), mask_quality(mask_b)]\n",
    "    valid = [(0.05 < q < 0.29) for q in qualities]\n",
    "    masks = [mask_r, mask_g, mask_b]\n",
    "    used = [m for m, v in zip(masks, valid) if v]\n",
    "    if not used:\n",
    "        return np.zeros_like(mask_r)\n",
    "    weight = 1.0 / len(used)\n",
    "    combined = sum(weight * m for m in used)\n",
    "    _, binary = cv2.threshold(combined.astype(np.uint8), threshold, 255, cv2.THRESH_BINARY)\n",
    "    return binary\n",
    "\n",
    "def get_binary_mask(obs, frame_count, center_color):\n",
    "    r, g, b = cv2.split(obs)\n",
    "    r_proc = adjust_saturation_single_channel(adjust_brightness(apply_gaussian_blur(r, 5), factor=0.9), factor=1.5)\n",
    "    g_proc = adjust_saturation_single_channel(adjust_brightness(apply_gaussian_blur(g, 5), factor=0.9), factor=1.5)\n",
    "    b_proc = adjust_saturation_single_channel(adjust_brightness(apply_gaussian_blur(b, 5), factor=0.9), factor=1.5)\n",
    "\n",
    "    if frame_count == 15:\n",
    "        r_val = extract_center_value(r)\n",
    "        g_val = extract_center_value(g)\n",
    "        b_val = extract_center_value(b)\n",
    "        center_color[:] = [r_val, g_val, b_val]\n",
    "\n",
    "    if center_color[0] is not None:\n",
    "        mask_r = extract_mask(r_proc, center_color[0])\n",
    "        mask_g = extract_mask(g_proc, center_color[1])\n",
    "        mask_b = extract_mask(b_proc, center_color[2])\n",
    "        mask = combine_masks(mask_r, mask_g, mask_b)\n",
    "        return mask\n",
    "    else:\n",
    "        return np.zeros_like(r)\n",
    "\n",
    "\n",
    "# --- Environment Setup ---\n",
    "env = gym.make(\"CarRacing-v2\", render_mode=\"human\", domain_randomize=True)\n",
    "obs, _ = env.reset()\n",
    "done = False\n",
    "\n",
    "# Initialize the BC model (pre-trained)\n",
    "\n",
    "bc_model= torch.load('expert_runs/model_full.pth')  # Load your BC model here\n",
    "bc_model.eval()\n",
    "\n",
    "# Initialize PPO model and optimizer\n",
    "ppo_model = PPO().to('cpu')\n",
    "optimizer = optim.Adam(ppo_model.parameters(), lr=0.001)\n",
    "\n",
    "# Stack for 4 grayscale images\n",
    "frame_stack = deque(maxlen=4)\n",
    "center_color = [None, None, None]\n",
    "frame_count = 0\n",
    "\n",
    "# Get initial binary mask for BC model (for teacher action)\n",
    "initial_mask = get_binary_mask(obs, frame_count, center_color) / 255.0  # normalize\n",
    "for _ in range(4):\n",
    "    frame_stack.append(initial_mask)\n",
    "\n",
    "# --- Training Loop ---\n",
    "def calculate_loss(alpha, beta, v, actions, old_log_probs, advantages, gamma=0.99, epsilon=0.1):\n",
    "    # Sample actions using Beta distribution\n",
    "    dist = Beta(alpha, beta)\n",
    "    action_log_probs = dist.log_prob(actions).sum()\n",
    "\n",
    "    # Compute the ratio (probability ratio between new and old policy)\n",
    "    ratio = torch.exp(action_log_probs - old_log_probs)\n",
    "\n",
    "    # Calculate surrogate loss (clipped version of PPO)\n",
    "    surr1 = ratio * advantages\n",
    "    surr2 = torch.clamp(ratio, 1.0 - epsilon, 1.0 + epsilon) * advantages\n",
    "    action_loss = -torch.min(surr1, surr2).mean()\n",
    "\n",
    "    # Value loss (smooth L1 loss between predicted value and target value)\n",
    "    advantages = torch.tensor([[advantages]], dtype=torch.float32).to(v.device)\n",
    "    value_loss = F.smooth_l1_loss(v, advantages)\n",
    "    \n",
    "    # Total loss: action loss + value loss\n",
    "    return action_loss + 2.0 * value_loss\n",
    "\n",
    "\n",
    "# Training loop\n",
    "while not done:\n",
    "    # Stack input images (normalize)\n",
    "    stack_np = np.stack(frame_stack, axis=0)\n",
    "    input_tensor = torch.tensor(stack_np, dtype=torch.float32).unsqueeze(0).to(device)  # (1, 4, 96, 96)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Teacher action (BC model) - used for initial training\n",
    "        bc_action = bc_model(input_tensor).squeeze().cpu().numpy()\n",
    "\n",
    "    # PPO model predicts alpha, beta (Beta distribution) and value (v)\n",
    "    alpha, beta, v = ppo_model(input_tensor)\n",
    "\n",
    "    # Sample action from Beta distribution\n",
    "    dist = Beta(alpha, beta)\n",
    "    action = dist.sample()\n",
    "\n",
    "    # Clip to [0, 1] because Beta distribution supports only (0, 1)\n",
    "    clipped_action = torch.clamp(action, 0.0, 1.0)\n",
    "\n",
    "    # Compute log probability before converting to NumPy\n",
    "    log_probs = dist.log_prob(clipped_action).sum()  # FIXED\n",
    "\n",
    "    # Rescale to [-1, 1] if needed by environment\n",
    "    rescaled_action = 2.0 * clipped_action - 1.0\n",
    "    env_action = rescaled_action.cpu().numpy()\n",
    "\n",
    "    # Store the transition for PPO learning\n",
    "    new_mask = get_binary_mask(obs, frame_count, center_color) / 255.0\n",
    "    frame_stack.append(new_mask)\n",
    "\n",
    "    # Compute reward and advantage (simplified)\n",
    "    reward = np.random.random()  # Simulated reward (replace with actual reward function)\n",
    "    advantage = reward - v.item()  # Simplified advantage\n",
    "\n",
    "    # Calculate the loss\n",
    "    ppo_loss = calculate_loss(alpha, beta, v, torch.tensor(action).to(device), log_probs, advantage)\n",
    "\n",
    "    # Backpropagate and update PPO parameters\n",
    "    optimizer.zero_grad()\n",
    "    ppo_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Step in the environment with the action\n",
    "    obs, _, terminated, truncated, _ = env.step(env_action)\n",
    "    done = terminated or truncated\n",
    "    frame_count += 1\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cefaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN ON RL\n",
    "\n",
    "import torch\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import cv2\n",
    "from collections import deque\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Beta\n",
    "\n",
    "\n",
    "# --- PPO Model ---\n",
    "class PPO(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PPO, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(4, 16, kernel_size=5, stride=2, padding=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2, padding=2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 6 * 6, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)  # Output alpha, beta for Beta distribution\n",
    "        self.fc3 = nn.Linear(128, 1)  # Output value function (v)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        alpha_beta = self.fc2(x)  # Parameters for Beta distribution\n",
    "        v = self.fc3(x)  # Value function\n",
    "        alpha, beta = torch.exp(alpha_beta[:, 0]), torch.exp(alpha_beta[:, 1])\n",
    "        return alpha, beta, v\n",
    "\n",
    "\n",
    "# --- Masking Pipeline (for BC model) ---\n",
    "def apply_gaussian_blur(channel, ksize=5):\n",
    "    return cv2.GaussianBlur(channel, (ksize, ksize), 0)\n",
    "\n",
    "def adjust_brightness(channel, factor=1.2):\n",
    "    channel = np.clip(np.float32(channel) * factor, 0, 255)\n",
    "    return np.uint8(channel)\n",
    "\n",
    "def adjust_saturation_single_channel(channel, factor=1.5):\n",
    "    rgb = cv2.merge([channel, channel, channel])\n",
    "    hsv = cv2.cvtColor(rgb, cv2.COLOR_RGB2HSV)\n",
    "    hsv[..., 1] = np.clip(hsv[..., 1] * factor, 0, 255)\n",
    "    saturated = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "    return cv2.cvtColor(saturated, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def extract_center_value(channel, region_size=7, offset_y=10):\n",
    "    h, w = channel.shape\n",
    "    cx, cy = w // 2, h // 2\n",
    "    offsets = [-offset_y, 0, offset_y]\n",
    "    values = []\n",
    "    for off in offsets:\n",
    "        y1 = cy + off - region_size // 2\n",
    "        y2 = cy + off + region_size // 2\n",
    "        x1 = cx - region_size // 2\n",
    "        x2 = cx + region_size // 2\n",
    "        region = channel[y1:y2, x1:x2]\n",
    "        values.append(np.mean(region))\n",
    "    return np.mean(values)\n",
    "\n",
    "def extract_mask(channel, center_value, tolerance=25):\n",
    "    diff = np.abs(channel.astype(np.int16) - int(center_value))\n",
    "    mask = np.uint8(diff < tolerance) * 255\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    return mask\n",
    "\n",
    "def mask_quality(mask):\n",
    "    white = np.sum(mask == 255)\n",
    "    total = mask.size\n",
    "    return white / total\n",
    "\n",
    "def combine_masks(mask_r, mask_g, mask_b, threshold=127):\n",
    "    qualities = [mask_quality(mask_r), mask_quality(mask_g), mask_quality(mask_b)]\n",
    "    valid = [(0.05 < q < 0.29) for q in qualities]\n",
    "    masks = [mask_r, mask_g, mask_b]\n",
    "    used = [m for m, v in zip(masks, valid) if v]\n",
    "    if not used:\n",
    "        return np.zeros_like(mask_r)\n",
    "    weight = 1.0 / len(used)\n",
    "    combined = sum(weight * m for m in used)\n",
    "    _, binary = cv2.threshold(combined.astype(np.uint8), threshold, 255, cv2.THRESH_BINARY)\n",
    "    return binary\n",
    "\n",
    "def get_binary_mask(obs, frame_count, center_color):\n",
    "    r, g, b = cv2.split(obs)\n",
    "    r_proc = adjust_saturation_single_channel(adjust_brightness(apply_gaussian_blur(r, 5), factor=0.9), factor=1.5)\n",
    "    g_proc = adjust_saturation_single_channel(adjust_brightness(apply_gaussian_blur(g, 5), factor=0.9), factor=1.5)\n",
    "    b_proc = adjust_saturation_single_channel(adjust_brightness(apply_gaussian_blur(b, 5), factor=0.9), factor=1.5)\n",
    "\n",
    "    if frame_count == 15:\n",
    "        r_val = extract_center_value(r)\n",
    "        g_val = extract_center_value(g)\n",
    "        b_val = extract_center_value(b)\n",
    "        center_color[:] = [r_val, g_val, b_val]\n",
    "\n",
    "    if center_color[0] is not None:\n",
    "        mask_r = extract_mask(r_proc, center_color[0])\n",
    "        mask_g = extract_mask(g_proc, center_color[1])\n",
    "        mask_b = extract_mask(b_proc, center_color[2])\n",
    "        mask = combine_masks(mask_r, mask_g, mask_b)\n",
    "        return mask\n",
    "    else:\n",
    "        return np.zeros_like(r)\n",
    "\n",
    "\n",
    "# --- Environment Setup ---\n",
    "env = gym.make(\"CarRacing-v2\", render_mode=\"human\", domain_randomize=True)\n",
    "obs, _ = env.reset()\n",
    "done = False\n",
    "\n",
    "# Load BC model (teacher)\n",
    "bc_model = torch.load('expert_runs/model_full.pth')  # Load BC model here\n",
    "bc_model.eval()\n",
    "\n",
    "# --- Training Loop for BC (Distillation Phase) ---\n",
    "frame_stack = deque(maxlen=4)\n",
    "center_color = [None, None, None]\n",
    "frame_count = 0\n",
    "\n",
    "# Get initial binary mask for BC model (for teacher action)\n",
    "initial_mask = get_binary_mask(obs, frame_count, center_color) / 255.0  # normalize\n",
    "for _ in range(4):\n",
    "    frame_stack.append(initial_mask)\n",
    "\n",
    "# Train PPO model using BC actions\n",
    "ppo_model = PPO().to(device)\n",
    "optimizer = optim.Adam(ppo_model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(5):\n",
    "    while not done:\n",
    "        # Stack input images (normalize)\n",
    "        stack_np = np.stack(frame_stack, axis=0)\n",
    "        input_tensor = torch.tensor(stack_np, dtype=torch.float32).unsqueeze(0).to(device)  # (1, 4, 96, 96)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # BC action (teacher)\n",
    "            bc_action = bc_model(input_tensor).squeeze().cpu().numpy()\n",
    "\n",
    "        # PPO model predicts alpha, beta (Beta distribution) and value (v)\n",
    "        alpha, beta, v = ppo_model(input_tensor)\n",
    "\n",
    "        # Sample action from Beta distribution\n",
    "        dist = Beta(alpha, beta)\n",
    "        action = dist.sample()\n",
    "\n",
    "        # Clip actions to ensure they stay within valid bounds (e.g., -1 to 1 for steering)\n",
    "        action = torch.clamp(action, -1.0, 1.0).cpu().numpy()\n",
    "\n",
    "        # Step in the environment with the action\n",
    "        obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        frame_count += 1\n",
    "\n",
    "        # Get new grayscale mask (used only for PPO input)\n",
    "        new_mask = get_binary_mask(obs, frame_count, center_color) / 255.0\n",
    "        frame_stack.append(new_mask)\n",
    "\n",
    "        # Simplified advantage (reward - value)\n",
    "        advantage = reward - v.item()\n",
    "\n",
    "        # Calculate the loss\n",
    "        ppo_loss = calculate_loss(alpha, beta, v, torch.tensor(action).to(device), log_probs, advantage)\n",
    "\n",
    "        # Backpropagate and update PPO parameters\n",
    "        optimizer.zero_grad()\n",
    "        ppo_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Now the PPO model should be ready to learn by itself\n",
    "\n",
    "# --- Training Loop for PPO (RL Phase) ---\n",
    "while not done:\n",
    "    # Stack input images (normalize)\n",
    "    stack_np = np.stack(frame_stack, axis=0)\n",
    "    input_tensor = torch.tensor(stack_np, dtype=torch.float32).unsqueeze(0).to(device)  # (1, 4, 96, 96)\n",
    "\n",
    "    # PPO model predicts alpha, beta (Beta distribution) and value (v)\n",
    "    alpha, beta, v = ppo_model(input_tensor)\n",
    "\n",
    "    # Sample action from Beta distribution\n",
    "    dist = Beta(alpha, beta)\n",
    "    action = dist.sample()\n",
    "\n",
    "    # Clip actions to ensure they stay within valid bounds (e.g., -1 to 1 for steering)\n",
    "    action = torch.clamp(action, -1.0, 1.0).cpu().numpy()\n",
    "\n",
    "    # Compute log probability for the actions predicted by PPO\n",
    "    log_probs = dist.log_prob(action).sum(dim=1, keepdim=True)\n",
    "\n",
    "    # Step in the environment with the action\n",
    "    obs, reward, terminated, truncated, _ = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    frame_count += 1\n",
    "\n",
    "    # Get new grayscale mask (used only for PPO input)\n",
    "    new_mask = get_binary_mask(obs, frame_count, center_color) / 255.0\n",
    "    frame_stack.append(new_mask)\n",
    "\n",
    "    # Simplified advantage (reward - value)\n",
    "    advantage = reward - v.item()\n",
    "\n",
    "    # Calculate the loss\n",
    "    ppo_loss = calculate_loss(alpha, beta, v, torch.tensor(action).to(device), log_probs, advantage)\n",
    "\n",
    "    # Backpropagate and update PPO parameters\n",
    "    optimizer.zero_grad()\n",
    "    ppo_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1158e606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed run_08.npz\n",
      "✅ Processed run_04.npz\n",
      "✅ Processed run_05.npz\n",
      "✅ Processed run_07.npz\n",
      "✅ Processed run_06.npz\n",
      "✅ Processed run_02.npz\n",
      "✅ Processed run_03.npz\n",
      "✅ Processed run_01.npz\n",
      "Total samples: 7511\n",
      "✅ Saved pretraining dataset to expert_runs/ppo_grayscale_dataset.npz (grayscale, compressed)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def process_and_save_grayscale_for_ppo(directory, output_filename=\"ppo_grayscale_dataset.npz\"):\n",
    "    files = [f for f in os.listdir(directory) if f.endswith('.npz')]\n",
    "    \n",
    "    if not files:\n",
    "        print(\"No .npz files found in the directory.\")\n",
    "        return\n",
    "\n",
    "    all_obs = []\n",
    "    all_actions = []\n",
    "\n",
    "    for file in files:\n",
    "        file_path = os.path.join(directory, file)\n",
    "        try:\n",
    "            data = np.load(file_path)\n",
    "\n",
    "            if 'masks' in data and 'acts' in data:\n",
    "                masks = data['masks']\n",
    "                actions = data['acts']\n",
    "\n",
    "                if len(masks) > 30:\n",
    "                    # Crop unnecessary frames\n",
    "                    masks = masks[11:-15]\n",
    "                    actions = actions[11:-15]\n",
    "\n",
    "                    # Normalize and ensure grayscale format\n",
    "                    masks = masks.astype(np.float32) / 255.0  # (N, 96, 96)\n",
    "                    masks = np.expand_dims(masks, axis=1)     # (N, 1, 96, 96) for grayscale channel\n",
    "\n",
    "                    all_obs.append(masks)\n",
    "                    all_actions.append(actions)\n",
    "\n",
    "                    print(f\"✅ Processed {file}\")\n",
    "                else:\n",
    "                    print(f\"⚠️ Skipped {file} — not enough frames.\")\n",
    "            else:\n",
    "                print(f\"⚠️ Skipped {file} — missing 'masks' or 'acts'.\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {file}: {e}\")\n",
    "\n",
    "    if all_obs and all_actions:\n",
    "        all_obs = np.concatenate(all_obs, axis=0)      # (N, 1, 96, 96)\n",
    "        all_actions = np.concatenate(all_actions, axis=0)  # (N, 3)\n",
    "\n",
    "        print(f\"Total samples: {len(all_obs)}\")\n",
    "\n",
    "        save_path = os.path.join(directory, output_filename)\n",
    "        np.savez_compressed(save_path, obs=all_obs, acts=all_actions)\n",
    "        print(f\"✅ Saved pretraining dataset to {save_path} (grayscale, compressed)\")\n",
    "    else:\n",
    "        print(\"❌ No valid data collected.\")\n",
    "\n",
    "# Run the function\n",
    "if __name__ == \"__main__\":\n",
    "    directory = \"expert_runs\"  # Replace this with your actual path\n",
    "    process_and_save_grayscale_for_ppo(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15d974a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "class CustomCNNFeatureExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: gym.spaces.Box, features_dim: int = 128):\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        # Assume obs shape is (4, 96, 96)\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(4, 16, kernel_size=5, stride=2, padding=2),  # (B, 4, 96, 96) → (B, 16, 48, 48)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=2, padding=2), # → (B, 32, 24, 24)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1), # → (B, 64, 12, 12)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1), # → (B, 64, 6, 6)\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        self._features_dim = 64 * 6 * 6\n",
    "\n",
    "    def forward(self, observations: torch.Tensor) -> torch.Tensor:\n",
    "        return self.cnn(observations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e7fc4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "from stable_baselines3.ppo import PPO\n",
    "\n",
    "class CustomCNNPolicy(ActorCriticPolicy):\n",
    "    def __init__(self, observation_space, action_space, lr_schedule, **kwargs):\n",
    "        super().__init__(\n",
    "            observation_space,\n",
    "            action_space,\n",
    "            lr_schedule,\n",
    "            features_extractor_class=CustomCNNFeatureExtractor,\n",
    "            features_extractor_kwargs=dict(features_dim=128),\n",
    "            **kwargs\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4fb4c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_ppo_with_bc(model, bc_dataset, device=\"cpu\", epochs=3):\n",
    "    model.policy.to(device)\n",
    "    optimizer = torch.optim.Adam(model.policy.parameters(), lr=1e-4)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    model.policy.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for obs, act in DataLoader(bc_dataset, batch_size=64, shuffle=True):\n",
    "            obs = obs.to(device)\n",
    "            act = act.to(device)\n",
    "\n",
    "            pred = model.policy.actor(obs)  # get predicted actions\n",
    "            loss = loss_fn(pred, act)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"🧪 Pretraining Epoch {epoch+1}, Loss: {total_loss:.6f}\")\n",
    "\n",
    "    model.policy.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6421eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CustomPreprocessingEnv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvec_env\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DummyVecEnv\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Create your grayscale-stacked environment (must return obs shape (4, 96, 96))\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mDummyVecEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mCustomPreprocessingEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgym\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCarRacing-v2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Create PPO model with custom CNN policy\u001b[39;00m\n\u001b[1;32m      7\u001b[0m ppo_model \u001b[38;5;241m=\u001b[39m PPO(CustomCNNPolicy, env, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, tensorboard_log\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./ppo_logs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/myenv38/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:30\u001b[0m, in \u001b[0;36mDummyVecEnv.__init__\u001b[0;34m(self, env_fns)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, env_fns: List[Callable[[], gym\u001b[38;5;241m.\u001b[39mEnv]]):\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs \u001b[38;5;241m=\u001b[39m [_patch_env(fn()) \u001b[38;5;28;01mfor\u001b[39;00m fn \u001b[38;5;129;01min\u001b[39;00m env_fns]\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m([\u001b[38;5;28mid\u001b[39m(env\u001b[38;5;241m.\u001b[39munwrapped) \u001b[38;5;28;01mfor\u001b[39;00m env \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs])) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs):\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     33\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou tried to create multiple environments, but the function to create them returned the same instance \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     34\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstead of creating different objects. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease read https://github.com/DLR-RM/stable-baselines3/issues/1151 for more information.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m         )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/myenv38/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:30\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, env_fns: List[Callable[[], gym\u001b[38;5;241m.\u001b[39mEnv]]):\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs \u001b[38;5;241m=\u001b[39m [_patch_env(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m fn \u001b[38;5;129;01min\u001b[39;00m env_fns]\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m([\u001b[38;5;28mid\u001b[39m(env\u001b[38;5;241m.\u001b[39munwrapped) \u001b[38;5;28;01mfor\u001b[39;00m env \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs])) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs):\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     33\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou tried to create multiple environments, but the function to create them returned the same instance \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     34\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstead of creating different objects. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease read https://github.com/DLR-RM/stable-baselines3/issues/1151 for more information.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m         )\n",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvec_env\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DummyVecEnv\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Create your grayscale-stacked environment (must return obs shape (4, 96, 96))\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m env \u001b[38;5;241m=\u001b[39m DummyVecEnv([\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mCustomPreprocessingEnv\u001b[49m(gym\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCarRacing-v2\u001b[39m\u001b[38;5;124m\"\u001b[39m))])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Create PPO model with custom CNN policy\u001b[39;00m\n\u001b[1;32m      7\u001b[0m ppo_model \u001b[38;5;241m=\u001b[39m PPO(CustomCNNPolicy, env, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, tensorboard_log\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./ppo_logs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CustomPreprocessingEnv' is not defined"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "# Create your grayscale-stacked environment (must return obs shape (4, 96, 96))\n",
    "env = DummyVecEnv([lambda: (gym.make(\"CarRacing-v2\"))])\n",
    "\n",
    "# Create PPO model with custom CNN policy\n",
    "ppo_model = PPO(CustomCNNPolicy, env, verbose=1, tensorboard_log=\"./ppo_logs\")\n",
    "\n",
    "# Pretrain using BC dataset\n",
    "bc_dataset = BehaviorCloningDataset(\"expert_runs/final_dataset.pt\")\n",
    "pretrain_ppo_with_bc(ppo_model, bc_dataset)\n",
    "\n",
    "# Fine-tune using RL\n",
    "ppo_model.learn(total_timesteps=200_000)\n",
    "\n",
    "# Save model\n",
    "ppo_model.save(\"ppo_finetuned_grayscale\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062eb2f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
